# Research Agent - Perplexity API Integration

Real-time research capabilities for the AI Content Pipeline using Perplexity's AI-powered search engine.

## ðŸŽ¯ Purpose

The Research Agent enhances content creation by providing:
- **Real-time data** and current statistics
- **Expert insights** and industry quotes  
- **Recent developments** and trends
- **Reliable sources** and citations
- **Market intelligence** for content accuracy

## ðŸ—ï¸ Architecture Integration

### Phase 2 Enhancement
This agent integrates as **Stage 1.5** in the content pipeline:

```
Stage 1: Outline â†’ Stage 1.5: Research â†’ Stage 2: Content â†’ Stage 3: SEO â†’ Stage 4: Publish
```

### Single Session Flow
- Maintains existing single-session architecture
- Research data flows through conversation context
- Backward compatible (works with `include_research=False`)

## ðŸ”§ Setup

### 1. API Key Configuration
```bash
# Edit the .env file
cp research_agent/.env.example research_agent/.env
nano research_agent/.env
```

Add your Perplexity API key:
```env
PERPLEXITY_API_KEY=your_perplexity_api_key_here
```

### 2. Get Perplexity API Key
1. Visit [Perplexity AI Settings](https://www.perplexity.ai/settings/api)
2. Create an account and generate an API key
3. Copy the key to your `.env` file

### 3. Install Dependencies
```bash
# Already included in main requirements.txt
pip install httpx python-dotenv
```

## ðŸ“Š Output Format

### Research Data Structure
```json
{
  "queries": [
    "Latest trends and statistics for AI Marketing in 2024",
    "Current best practices and expert insights on Marketing Automation",
    "Recent developments and case studies in artificial intelligence"
  ],
  "results": [
    {
      "query": "Latest trends and statistics for AI Marketing in 2024",
      "answer": "AI marketing has seen significant growth...",
      "sources": ["https://example.com/source1", "McKinsey Report 2024"],
      "token_usage": {"prompt_tokens": 150, "completion_tokens": 800}
    }
  ],
  "statistics": [
    "AI marketing tools market grew by 35% in 2024",
    "$15.7 billion global AI marketing market size",
    "73% of marketers report improved ROI with AI tools"
  ],
  "expert_quotes": [
    "AI is transforming how we understand customer behavior",
    "Marketing automation will become essential for competitive advantage"
  ],
  "sources": [
    "https://www.mckinsey.com/ai-marketing-report-2024",
    "Harvard Business Review",
    "Gartner Research"
  ],
  "metadata": {
    "total_queries": 3,
    "successful_queries": 3,
    "processing_time": 12.5,
    "timestamp": 1699123456,
    "model": "llama-3.1-sonar-large-128k-online"
  }
}
```

## ðŸ” Research Query Generation

### Automatic Query Extraction
The agent analyzes outline content and generates 3-5 targeted research queries:

1. **Main Topic Query**: Latest trends for the primary subject
2. **Section Queries**: Best practices for each major section
3. **Keyword Queries**: Recent developments for target keywords  
4. **Industry Data**: Market statistics and growth data
5. **Expert Insights**: Thought leadership and case studies

### Example Queries Generated
For an outline about "AI Marketing Automation":
```
1. "Latest trends and statistics for AI Marketing Automation in 2024"
2. "Current best practices and expert insights on Marketing Automation"
3. "Recent developments and case studies in artificial intelligence"
4. "Market size, growth statistics for marketing automation tools"
5. "Expert opinions on AI marketing transformation"
```

## ðŸ› ï¸ Usage

### Standalone Usage
```python
from research_agent.agent import research_agent

# Conduct research on outline content
outline = """
# AI Marketing Guide
## Introduction to AI Marketing
## Marketing Automation Tools
## ROI and Analytics
"""

research_data = await research_agent.conduct_research(outline)
print(f"Found {len(research_data['statistics'])} statistics")
```

### Pipeline Integration
```python
# Automatically integrated in pipeline_single_session.py
result = await orchestrator.run_pipeline(
    topic="AI Marketing", 
    include_research=True  # Enable research stage
)
```

### API Usage
```bash
curl -X POST \
  -H "Authorization: Bearer demo-key-001" \
  -H "Content-Type: application/json" \
  -d '{
    "topic": "AI Marketing Automation",
    "include_research": true,
    "format": "wordpress"
  }' \
  http://localhost:8000/generate-content
```

## âš™ï¸ Configuration

### Environment Variables
```env
# Required
PERPLEXITY_API_KEY=your_api_key_here

# Optional Configuration
RESEARCH_MAX_QUERIES=5          # Maximum queries per research session
RESEARCH_TIMEOUT=30             # Request timeout in seconds
RESEARCH_RETRY_DELAY=2          # Delay between retries
RESEARCH_MAX_RETRIES=3          # Maximum retry attempts
PERPLEXITY_MODEL=llama-3.1-sonar-large-128k-online
```

### Model Options
- `llama-3.1-sonar-large-128k-online` (default) - Best for comprehensive research
- `llama-3.1-sonar-small-128k-online` - Faster, more cost-effective
- `llama-3.1-sonar-huge-128k-online` - Maximum capability

## ðŸ”„ Error Handling

### Graceful Degradation
- **No API Key**: Returns empty research data, pipeline continues
- **API Failures**: Logs errors, returns fallback data
- **Rate Limits**: Automatic retry with exponential backoff
- **Timeouts**: Continues with partial results

### Error Response Format
```json
{
  "query": "Research question",
  "answer": "Error description",
  "sources": [],
  "error": "HTTP 429" // or "Timeout", "Max retries exceeded"
}
```

## ðŸ“ˆ Performance Metrics

### Typical Performance
- **Query Generation**: ~0.5 seconds
- **Research Execution**: 2-5 seconds per query  
- **Total Research Time**: 10-25 seconds for 5 queries
- **Data Quality**: 15+ statistics, 10+ expert quotes, 20+ sources

### Cost Optimization
- Smart query generation (avoid redundant searches)
- Configurable query limits
- Efficient data extraction
- Request batching and caching

## ðŸ§ª Testing

### Basic Functionality Test
```python
import asyncio
from research_agent.agent import research_agent

async def test_research():
    outline = "# Test Topic\n## Section 1\n## Section 2"
    data = await research_agent.conduct_research(outline)
    assert len(data["queries"]) >= 3
    assert "metadata" in data
    print("âœ… Research agent working")

asyncio.run(test_research())
```

### API Key Validation
```bash
# Test API connectivity
python3 -c "
import asyncio
from research_agent.agent import research_agent
async def test():
    result = await research_agent.query_perplexity('test query')
    print('API Status:', 'OK' if 'error' not in result else 'FAILED')
asyncio.run(test())
"
```

## ðŸ”’ Security & Privacy

### API Key Security
- Store keys in `.env` files (never commit to git)
- Use environment variables in production
- Rotate keys regularly
- Monitor API usage

### Data Privacy
- No personal data in research queries
- Temporary storage only during pipeline execution
- Research results cleaned after 24 hours
- No persistent caching of API responses

## ðŸš¨ Troubleshooting

### Common Issues

#### API Key Not Working
```bash
# Verify API key format
echo $PERPLEXITY_API_KEY | grep -E '^pplx-[a-zA-Z0-9]{40,}$'

# Test API access
curl -H "Authorization: Bearer $PERPLEXITY_API_KEY" \
     -H "Content-Type: application/json" \
     -d '{"model":"llama-3.1-sonar-large-128k-online","messages":[{"role":"user","content":"test"}]}' \
     https://api.perplexity.ai/chat/completions
```

#### Research Stage Not Running
```python
# Check integration
from pipeline_single_session import SingleSessionPipelineOrchestrator
orchestrator = SingleSessionPipelineOrchestrator()
print("Research enabled:", hasattr(orchestrator, 'enable_research'))
```

#### Empty Research Results
```python
# Debug query generation
from research_agent.agent import research_agent
queries = research_agent.extract_research_queries("your outline here")
print("Generated queries:", queries)
```

### Log Analysis
```bash
# Check research logs
grep "research" /home/joel/ai-content-pipeline/api/api.log
grep "Perplexity" /home/joel/ai-content-pipeline/api/api.log
```

## ðŸ”— Integration Points

### Pipeline Integration
- **Input**: Outline content from Stage 1
- **Output**: Research data for Stage 2 content creation
- **Flow**: Maintains single session conversation
- **Fallback**: Graceful degradation if research fails

### API Integration
- **Parameter**: `include_research: bool` in ContentRequest
- **Response**: Research metadata in job status
- **Monitoring**: Research success/failure tracking

### Agent Communication
- Research data flows through conversation context
- Content agent receives structured research prompts
- SEO agent can reference research sources
- Publishing agent includes source attributions

## ðŸ“š Example Integration

### Complete Pipeline with Research
```python
# 1. Generate outline
outline = await orchestrator.run_agent_in_session(
    'outline_generator', 
    "Create outline for AI Marketing"
)

# 2. Conduct research (NEW STAGE 1.5)
research_data = await orchestrator.run_research_stage(outline)

# 3. Create content with research
content = await orchestrator.run_agent_in_session(
    'research_content_creator',
    f"Write article using this research data: {json.dumps(research_data)}"
)
```

## ðŸ“‹ Roadmap

### Phase 2 Features (Current)
- âœ… Perplexity API integration
- âœ… Automatic query generation
- âœ… Research data extraction
- âœ… Pipeline integration

### Phase 3 Enhancements (Future)
- [ ] Multiple research source integration
- [ ] Research result caching
- [ ] Custom query templates
- [ ] Research quality scoring
- [ ] Competitive analysis features

---

**Research Agent Status**: Production Ready âœ…  
**API**: Perplexity AI Sonar Models  
**Integration**: Single Session Pipeline Stage 1.5  
**Fallback**: Graceful degradation without API key